title: DADA Loop For Product Managers
author: Michael Magan
email: michael@magan.info
date: 13-09-2017

{% extends "post.html" %}
{% block body %}

{% load markup %}
{% filter markdown %}
#### What is a DADA loop?

DADA stands for Data, Analysis, Decision, Action. Its a varient of the OODA loop used by the airforce to help pilots make quick descions when facing a changing enviroment. DADA was adopeted by the CIA as their version to help train field agents on how to make quick decsions as well. People who can cycle through this loop more quickly can react with greater efficacy and speed.

#### Why is this useful for Product Managers?

Product managers are often the people notified of crisis and are expected to make decisions around, priority, communicating with those affected, and trade-offs. In crisis mode to take a step back and quickly iterate through a DADA loop can help product managers keep their calm and make data driven solutions even in the face of critical issues.

#### Is this useful only for Product Managers?
This or the OODA loop could be generally applicable in any kind of problem solving or strategy role. The type of data you use and your resolutions would look different, but the value of the iterative loop could help in more applications than just product managment.

#### The Value of DADA loops

Here are some of the major benefits I see from using DADA loops.

######Reduces Stress and Anxiety During Crisis
Instead of panic, just think "what data do I have", "what result can that data give me", "what should I do based on the data?", "What action can I take? What action can I take to get more data?"

###### Data Driven Resolutions
Because your loop always starts with data and analysis it forces your response to crisis to be data driven and not reactionary. You can use the DADA loop to help others resolve crisis based on data instead of emotion.

###### Helps Define Status
Because your are looping throught the DADA loop when asked you can give a clear train of thought, you can also express where your are in your investigation and resolution.

I wanted to provide an example of where I used this methodology during a _crisis_ on my product team.

#### Random Score Crisis

My team and I route leads to sales. We have millions of potential customers in our database of varying quality. In an effort to ensure that lead fed reps work the highest value leads we score them using models. Recently, wewanted to start routing some randomly scored leads for a few reason. Firstly, to establish a baseline of the value the scoring generated over just randomly assinging leads. Secondly, to identify leads that traditionally are not considered valuable (based on available research) but my offer value to sales.

At the same time we had also identified and were in the process of resolving another issue that had caused our score qualified leads to no longer send as much volume. A day after turning on the new random test group there was a huge spike in leads assinged via this method. This "data" is what started our DADA loop.

###### Loop One
* Data: Unusually high spike in assignments. 
* Analysis: This could be due to a catch affect in leads that weren't assigned before but are now able to be assigned
* Decision: We should look that data to see if this spike is close in size to the diff in what we sent before and after the issue
* Action: I looked the spike, and the time before and after the issue

###### Loop Two
* Data: The spike is multiples larger than assignment diff from the issue.
* Analysis: Its likely something else that caused this spike
* Descion: Identify the next likely culprit
* Action: Look at the test we launched the same day.

###### Loop Three
* Data: The random group is many multiples in size larger than the other two groups and the other two groups also aren't similar sizes either.
* Analysis: There is soemthing wrong with how the test was set up.
* Decsion: Identify why we sent so many more random than the other two groups.
* Action: Look at test group score compisitions.

###### Loop Four
* Data: The percentiles distribtuions for each score wasn't uniform. (more detail below)
* Analysis: The data we trained our models on differes from the data we use during production. The legacy model's distribution was also far from true.
* Decsion: Turn off random test group. Recalculate distribtuions, and change assingment thresholds to match reality.
* Action: Turn off test group. Created issues and prioritized their resolution.

Detail as promised. To be able to compare between models we decided to use percentiles instead of raw scores since they raw scores weren't always comparable. For example, scores could be probablities, expected value, or the output of linear regression. So we scored everything and then bucketed scores into one thousands buckets to provide score granulairty down to 1/10th of a percent.

We then had percentile thresholds below which we didn't assign. We expected close to a uniform distribution form these precentile groups. However only random met that the other two highly were right-skewed. The uniform distribtuion had many multiple more leads above our threshold than the other two groups. This discovery led to both the root cause and the resolution.

#### Conclusion
DADA loop help me focus on the real root cause of the issue and focus on finding the data to resolve the issue. I hope that using DADA loops helps you resolve crisis better.

{% endfilter %}
{% endblock %}